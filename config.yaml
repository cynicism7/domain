literature_dirs:
  - "./papers"
extensions:
  - ".pdf"
llm:
  provider: "openai_api"
  model: "DeepSeek-R1-0528-Qwen3-8B"
  api_base: "http://127.0.0.1:1234/v1"
  api_key: "lm-studio"
  # max_tokens = 模型「最多生成」的 token 数（不是整段对话总量）。二选一只需一行 JSON，128 够用；若被截断再改为 256
  max_tokens: 128
  temperature: 0.0
# 送交的文献内容上限（仅标题/作者/研究团队/摘要），越小越快
max_chars_for_llm: 800
output:
  db_path: "./literature_domains.db"
  export_csv: True
  csv_path: "./literature_domains.csv"
